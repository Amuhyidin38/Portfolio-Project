{"cells":[{"cell_type":"markdown","source":["# Task 1\n","\n","The marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\n","Create a cleaned version of the dataframe:\n","\n","- Start with the data in the file `raw_customer_data.csv`\n","- Your output should be a DataFrame named `clean_data`\n","- All column names and values should match the table below.\n","</br>\n","\n","| Column Name | Criteria |\n","|------------|----------|\n","| customer_id | Integer. Unique identifier for each customer. No missing values. |\n","| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n","| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n","| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n","| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n","| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n","| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |"],"metadata":{"id":"p2qA0ZToDEFG"},"id":"p2qA0ZToDEFG"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3b157b1","executionInfo":{"status":"ok","timestamp":1759057054613,"user_tz":-540,"elapsed":1478,"user":{"displayName":"Agus Muhyidin","userId":"13797967783706086394"}},"outputId":"d8abaa54-0c3a-49ba-ced0-d50e2a6146b1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"e3b157b1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Tempel path yang sudah disalin di sini\n","path = '/content/drive/MyDrive/Colab Notebooks/AI Engineering/For Project/CustomerPurchasePrediction/raw_customer_data.csv'\n","df = pd.read_csv(path)"],"metadata":{"id":"h5g0aYRcBU-M","executionInfo":{"status":"ok","timestamp":1759058028385,"user_tz":-540,"elapsed":30,"user":{"displayName":"Agus Muhyidin","userId":"13797967783706086394"}}},"id":"h5g0aYRcBU-M","execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":22,"id":"5ce18b54-29af-4beb-bc8c-79c4e21bcd52","metadata":{"executionCancelledAt":null,"executionTime":3559,"lastExecutedAt":1734267722349,"lastExecutedByKernel":"c39ffbb6-e0ca-41c5-8cc1-72c54c0885ac","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Write your answer to Task 1 here \nimport pandas as pd\n\ndef clean_data():\n    raw_data = pd.read_csv('raw_customer_data.csv')\n    raw_data['time_spent'] = raw_data['time_spent'].fillna(raw_data['time_spent'].median())\n    raw_data['pages_viewed'] = raw_data['pages_viewed'].fillna(raw_data['pages_viewed'].mean())\n    raw_data['basket_value'] = raw_data['basket_value'].fillna(0)\n    raw_data['device_type'] = raw_data['device_type'].fillna('Unknown')\n    raw_data['customer_type'] = raw_data['customer_type'].fillna('New')\n    raw_data['pages_viewed'] = raw_data['pages_viewed'].round().astype(int)\n    return raw_data\n\nclean_data = clean_data()\nprint(clean_data.head())\n","outputsMetadata":{"0":{"height":332,"type":"stream"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"5ce18b54-29af-4beb-bc8c-79c4e21bcd52","executionInfo":{"status":"ok","timestamp":1759058062262,"user_tz":-540,"elapsed":79,"user":{"displayName":"Agus Muhyidin","userId":"13797967783706086394"}},"outputId":"5c76e7f0-1509-4a02-d070-0650a0d68064"},"outputs":[{"output_type":"stream","name":"stdout","text":["First few rows of cleaned data:\n","   customer_id  time_spent  pages_viewed  basket_value device_type  \\\n","0            1   23.097867             7     50.574647      Mobile   \n","1            2   57.092144             3     56.891022      Mobile   \n","2            3   44.187643            14      8.348296      Mobile   \n","3            4   36.320851            10     43.481489      Mobile   \n","4            5   10.205100            16      0.000000      Mobile   \n","\n","  customer_type  purchase  \n","0     Returning         0  \n","1     Returning         1  \n","2     Returning         0  \n","3           New         1  \n","4     Returning         1  \n","\n","DataFrame info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 500 entries, 0 to 499\n","Data columns (total 7 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   customer_id    500 non-null    int64  \n"," 1   time_spent     500 non-null    float64\n"," 2   pages_viewed   500 non-null    int64  \n"," 3   basket_value   500 non-null    float64\n"," 4   device_type    500 non-null    object \n"," 5   customer_type  500 non-null    object \n"," 6   purchase       500 non-null    int64  \n","dtypes: float64(2), int64(3), object(2)\n","memory usage: 27.5+ KB\n","None\n","\n","Summary statistics:\n","       customer_id  time_spent  pages_viewed  basket_value    purchase\n","count   500.000000  500.000000    500.000000    500.000000  500.000000\n","mean    250.500000   34.426240      9.712000     41.392726    0.814000\n","std     144.481833   14.394196      5.287056     31.234606    0.389496\n","min       1.000000    6.945902      1.000000      0.000000    0.000000\n","25%     125.750000   22.804324      5.750000     14.055365    1.000000\n","50%     250.500000   35.037329      9.000000     41.079586    1.000000\n","75%     375.250000   45.611368     14.000000     64.022576    1.000000\n","max     500.000000   59.584923     19.000000    130.530372    1.000000\n","\n","Cleaned data has been saved to 'cleaned_customer_data.csv'\n"]}],"source":["\n","import pandas as pd\n","import numpy as np\n","\n","# Path File\n","path = '/content/drive/MyDrive/Colab Notebooks/AI Engineering/For Project/CustomerPurchasePrediction/raw_customer_data.csv'\n","df = pd.read_csv(path)\n","\n","# 1. Handle missing values according to specifications\n","# For time_spent: Replace missing values with median\n","time_spent_median = df['time_spent'].median()\n","df['time_spent'] = df['time_spent'].fillna(time_spent_median)\n","\n","# For pages_viewed: Replace missing values with mean (after converting to float if needed)\n","if df['pages_viewed'].dtype == 'object':\n","    # Handle any non-numeric values if they exist\n","    df['pages_viewed'] = pd.to_numeric(df['pages_viewed'], errors='coerce')\n","pages_viewed_mean = df['pages_viewed'].mean()\n","df['pages_viewed'] = df['pages_viewed'].fillna(pages_viewed_mean).astype(int)  # Convert to int as required\n","\n","# For basket_value: Replace missing values with 0\n","df['basket_value'] = df['basket_value'].fillna(0)\n","\n","# For device_type: Replace missing values with \"Unknown\"\n","df['device_type'] = df['device_type'].fillna('Unknown')\n","\n","# For customer_type: Replace missing values with \"New\"\n","df['customer_type'] = df['customer_type'].fillna('New')\n","\n","# 2. Ensure data types are correct\n","df['customer_id'] = df['customer_id'].astype(int)\n","df['time_spent'] = df['time_spent'].astype(float)\n","df['pages_viewed'] = df['pages_viewed'].astype(int)\n","df['basket_value'] = df['basket_value'].astype(float)\n","df['purchase'] = df['purchase'].astype(int)\n","\n","# 3. Standardize categorical values (in case there are variations in case or extra spaces)\n","df['device_type'] = df['device_type'].str.title().str.strip()\n","df['customer_type'] = df['customer_type'].str.title().str.strip()\n","\n","# 4. Validate categorical values\n","valid_devices = ['Mobile', 'Desktop', 'Tablet', 'Unknown']\n","valid_customer_types = ['New', 'Returning']\n","\n","df['device_type'] = df['device_type'].apply(lambda x: x if x in valid_devices else 'Unknown')\n","df['customer_type'] = df['customer_type'].apply(lambda x: x if x in valid_customer_types else 'New')\n","\n","# Create the clean_data DataFrame\n","clean_data = df.copy()\n","\n","# Display the first few rows of the cleaned data\n","print(\"First few rows of cleaned data:\")\n","print(clean_data.head())\n","\n","# Display information about the cleaned data\n","print(\"\\nDataFrame info:\")\n","print(clean_data.info())\n","\n","# Display summary statistics\n","print(\"\\nSummary statistics:\")\n","print(clean_data.describe())\n","\n","# Save the cleaned data to a CSV file (optional)\n","clean_data.to_csv('cleaned_customer_data.csv', index=False)\n","print(\"\\nCleaned data has been saved to 'cleaned_customer_data.csv'\")\n","\n","# Note: The clean_data DataFrame is now ready for use in the notebook\n"]},{"cell_type":"markdown","metadata":{"id":"90c2fc00"},"source":["You can mount your Google Drive to access files stored there directly from this notebook.\n","\n","Run the following cell to mount your Drive. This will prompt you to authorize Colab to access your Google Drive files."],"id":"90c2fc00"},{"cell_type":"markdown","metadata":{"id":"416c6a85"},"source":["Once your drive is mounted, you can navigate to the desired directory and copy files using standard Python file operations or shell commands.\n","\n","For example, to copy a file named `my_file.csv` from a folder named `MyFolder` in your Google Drive to the current directory in Colab, you can use this command:"],"id":"416c6a85"},{"cell_type":"markdown","id":"026b3c30-d3b0-4762-ae10-0f2880873bdc","metadata":{"id":"026b3c30-d3b0-4762-ae10-0f2880873bdc"},"source":["# Task 2\n","The pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\n","Create the model features:\n","\n","- Start with the data in the file `model_data.csv`\n","- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n","- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n","    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n","- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n"]},{"cell_type":"code","execution_count":25,"id":"6d47e440-c4ab-45cf-af40-53181764bac4","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1734267789060,"lastExecutedByKernel":"c39ffbb6-e0ca-41c5-8cc1-72c54c0885ac","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef prepare_features():\n    df = pd.read_csv('model_data.csv')\n    scaler = MinMaxScaler()\n    numerical_cols = ['time_spent', 'pages_viewed', 'basket_value']\n    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n    df = pd.get_dummies(df, columns=['device_type', 'customer_type'], drop_first=False)\n    return df\n\nmodel_features = prepare_features()\nprint(model_features.head())\n\n","outputsMetadata":{"0":{"height":332,"type":"stream"}},"id":"6d47e440-c4ab-45cf-af40-53181764bac4","outputId":"8120c800-a3d8-413a-9f0c-e85195114c02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759058239681,"user_tz":-540,"elapsed":56,"user":{"displayName":"Agus Muhyidin","userId":"13797967783706086394"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["model_feature_set preview:\n","   customer_id  time_spent  pages_viewed  basket_value  purchase  \\\n","0          501    0.664167      0.500000      0.000000         1   \n","1          502    0.483681      0.222222      0.524981         1   \n","2          503    0.231359      0.111111      0.457291         0   \n","3          504    0.792944      0.277778      0.000000         1   \n","4          505    0.649210      0.166667      0.484283         1   \n","\n","   device_type_Desktop  device_type_Mobile  device_type_Tablet  \\\n","0                 True               False               False   \n","1                False                True               False   \n","2                False                True               False   \n","3                False               False               False   \n","4                False               False                True   \n","\n","   device_type_Unknown  customer_type_New  customer_type_Returning  \n","0                False               True                    False  \n","1                False              False                     True  \n","2                False              False                     True  \n","3                 True               True                    False  \n","4                False               True                    False  \n","\n","Columns in model_feature_set:\n","['customer_id', 'time_spent', 'pages_viewed', 'basket_value', 'purchase', 'device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet', 'device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\n","\n","Saved feature set to: /content/model_feature_set.csv\n"]}],"source":["# Write your answer to Task 2 here\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from pathlib import Path\n","\n","# Path File\n","path = '/content/drive/MyDrive/Colab Notebooks/AI Engineering/For Project/CustomerPurchasePrediction/model_data.csv'\n","df = pd.read_csv(path)\n","\n","# Columns per task specification\n","numeric_features = ['time_spent', 'pages_viewed', 'basket_value']\n","categorical_features = ['device_type', 'customer_type']\n","\n","# 1) Scale numeric features to 0-1 range (Min-Max)\n","scaler = MinMaxScaler()\n","df[numeric_features] = scaler.fit_transform(df[numeric_features])\n","\n","# 2) One-hot encode categorical features with the required naming format\n","#    This will create columns like 'device_type_Desktop', 'customer_type_New', etc.\n","df_dummies = pd.get_dummies(df[categorical_features], prefix=categorical_features)\n","\n","# 3) Build the final feature set: all original columns except the categorical ones, plus the one-hot columns\n","model_feature_set = pd.concat([\n","    df.drop(columns=categorical_features),\n","    df_dummies\n","], axis=1)\n","\n","# Optional: persist to disk for downstream use\n","output_path = Path.cwd() / 'model_feature_set.csv'\n","model_feature_set.to_csv(output_path, index=False)\n","\n","# Quick sanity outputs\n","print('model_feature_set preview:')\n","print(model_feature_set.head())\n","print('\\nColumns in model_feature_set:')\n","print(list(model_feature_set.columns))\n","print(f\"\\nSaved feature set to: {output_path}\")"]},{"cell_type":"markdown","id":"10a02327-d528-441c-87bf-098f9d6415e1","metadata":{"id":"10a02327-d528-441c-87bf-098f9d6415e1"},"source":["# Task 3\n","\n","Now that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n","\n","- Using PyTorch, create a network with:\n","   - At least one hidden layer with 8 units\n","   - ReLU activation for hidden layer\n","   - Sigmoid activation for the output layer\n","- Using the prepared features in `input_model_features.csv`, train the model to predict purchases.\n","- Use the validation dataset `validation_features.csv` to predict new values based on the trained model.\n","- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n"]},{"cell_type":"code","source":["!pip install torch torchvision torchaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4lV__DMDoNx","executionInfo":{"status":"ok","timestamp":1759058518469,"user_tz":-540,"elapsed":6979,"user":{"displayName":"Agus Muhyidin","userId":"13797967783706086394"}},"outputId":"06a3b31b-d331-46b5-e61a-2f40ee940cd5"},"id":"F4lV__DMDoNx","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0ae19a5","executionInfo":{"status":"ok","timestamp":1759058719440,"user_tz":-540,"elapsed":7987,"user":{"displayName":"Agus Muhyidin","userId":"13797967783706086394"}},"outputId":"ffb02437-ad24-49c5-bf22-7d3d03e31f5c"},"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Assuming model_feature_set is already loaded and preprocessed\n","# If not, you would need to load it here:\n","# model_feature_set = pd.read_csv('model_feature_set.csv')\n","\n","# Separate features and target\n","# Drop customer_id before splitting as it's not a feature for training\n","X = model_feature_set.drop(columns=[\"customer_id\", \"purchase\"])\n","y = model_feature_set[\"purchase\"]\n","customer_ids = model_feature_set[\"customer_id\"] # Keep customer_ids for the final output\n","\n","# Convert boolean columns to integers for PyTorch compatibility\n","for col in X.columns:\n","    if X[col].dtype == 'bool':\n","        X[col] = X[col].astype(int)\n","\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val, train_ids, val_ids = train_test_split(\n","    X, y, customer_ids, test_size=0.2, random_state=42\n",")\n","\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n","\n","\n","# Define the neural network\n","class PurchaseNet(nn.Module):\n","    def __init__(self, input_dim):\n","        super(PurchaseNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 8)\n","        self.relu = nn.ReLU()\n","        self.output = nn.Linear(8, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.output(x)\n","        return self.sigmoid(x)\n","\n","# Initialize model\n","input_dim = X_train.shape[1]\n","purchase_model = PurchaseNet(input_dim)\n","\n","# Training setup\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(purchase_model.parameters(), lr=0.01)\n","epochs = 100\n","\n","# Training loop\n","losses = []\n","for epoch in range(epochs):\n","    purchase_model.train()\n","    optimizer.zero_grad()\n","    outputs = purchase_model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())\n","\n","    # Print loss every 10 epochs\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n","\n","\n","# Predict on validation set\n","purchase_model.eval()\n","with torch.no_grad():\n","    predictions = purchase_model(X_val_tensor).numpy().flatten()\n","\n","# Create output DataFrame\n","validation_predictions = pd.DataFrame({'customer_id': val_ids, 'purchase': predictions})\n","validation_predictions[\"purchase\"] = (validation_predictions[\"purchase\"] > 0.5).astype(int)\n","\n","# Display the first few rows of the predictions\n","print(\"\\nFirst few rows of validation predictions:\")\n","print(validation_predictions.head())\n","\n","# The purchase_model is now trained and validation_predictions DataFrame is created."],"id":"f0ae19a5","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.5492\n","Epoch [20/100], Loss: 0.5048\n","Epoch [30/100], Loss: 0.5009\n","Epoch [40/100], Loss: 0.4904\n","Epoch [50/100], Loss: 0.4826\n","Epoch [60/100], Loss: 0.4749\n","Epoch [70/100], Loss: 0.4673\n","Epoch [80/100], Loss: 0.4602\n","Epoch [90/100], Loss: 0.4548\n","Epoch [100/100], Loss: 0.4512\n","\n","First few rows of validation predictions:\n","     customer_id  purchase\n","361          862         1\n","73           574         1\n","374          875         1\n","155          656         0\n","104          605         1\n"]}]},{"cell_type":"code","execution_count":null,"id":"4eed72b0","metadata":{"id":"4eed72b0"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"}},"nbformat":4,"nbformat_minor":5}